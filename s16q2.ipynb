{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71c45610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets embrace it, and then face it because we dont know what's there for us. Mai HU gyiaaan maera gana hai surila. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/stranger/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/stranger/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "text = \"\"\"Mai HU gyiaaan maera gana hai surila. YOu are noob, I'm pro, but who know what will be the future.\n",
    "Lets embrace it, and then face it because we dont know what's there for us. SO lets runnnnnnnn, runnn runnn from\n",
    "the procarsination. LOl dont run from your problems\"\"\"\n",
    "\n",
    "processed_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "tokens = word_tokenize(processed_text)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "freq_dist = FreqDist(filtered_tokens)\n",
    "\n",
    "summary_sentences = []\n",
    "for sentence in sent_tokenize(text):\n",
    "    sentence_tokens = word_tokenize(sentence)\n",
    "    sentence_score = sum([freq_dist[token] for token in sentence_tokens])\n",
    "    summary_sentences.append((sentence, sentence_score))\n",
    "\n",
    "summary_sentences.sort(key=lambda x: x[1], reverse=True)\n",
    "summary = ''\n",
    "for sentence in summary_sentences[:2]:\n",
    "    summary += sentence[0] + ' '\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c040d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
